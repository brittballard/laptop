# 1.2 Procedures and the Processes They Generate

Procedures generate common shapes for processes.
Processes consume computational resources of time and space at different rates.

## 1.2.1 Linear Recursion and Iteration

This factorial procedure generates a linear recursive process:

```lisp
(define (factorial n)
  (if (= n 1)
      1
      (* n (factorial (- n 1)))))
```

Its shape looks like this:

```
(factorial 6)
(* 6 (factorial 5))
(* 6 (* 5 (factorial 4)))
(* 6 (* 5 (* 4 (factorial 3))))
(* 6 (* 5 (* 4 (* 3 (factorial 2)))))
(* 6 (* 5 (* 4 (* 3 (* 2 (factorial 1))))))
(* 6 (* 5 (* 4 (* 3 (* 2 1)))))
(* 6 (* 5 (* 4 (* 3 2))))
(* 6 (* 5 (* 4 6)))
(* 6 (* 5 24))
(* 6 120)
720
```

The process expands and then contracts.
The expansion occurs as the process builds up
a chain of deferred operations (in this case, a chain of multiplications).
The contraction occurs as the operations are actually performed.
Carrying out this process requires that
the interpreter keep track of the operations to be performed later on.

In the computation of `n!`,
the length of the chain of deferred multiplications,
and hence the amount of information needed to keep track of it,
grows linearly with `n` (is proportional to `n`),
like the number of steps.

This factorial procedure generates a linear iterative process:

```lisp
(define (factorial n)
  (fact-iter 1 1 n))

(define (fact-iter product counter max-count)
  (if (> counter max-count)
      product
      (fact-iter (* counter product)
                 (+ counter 1)
                 max-count)))
```

Its shape looks like this:

```
(factorial 6)
(fact-iter 1 1 6)
(fact-iter 1 2 6)
(fact-iter 2 3 6)
(fact-iter 6 4 6)
(fact-iter 24 5 6)
(fact-iter 120 6 6)
(fact-iter 720 7 6)
720
```

This process does not expand and contract.
At each step for `n`,
it keeps track of the current values of the variables
`product`, `counter`, and `max-count`.

An iterative process has a fixed number of state variables,
a fixed rule describing how vars should be updated
as the process moves from state to state,
and an (optional) end test
that specifies conditions under which the process should terminate.

In computing `n!`, the number of steps required grows linearly with `n`.

In the iterative case,
vars provide a complete description of the process state at any point.
If the computation stopped between steps,
the computation can be resumed by supplying the interpreter
with the values of the three program variables.

With the recursive process,
there is additional info maintained by the interpreter
not contained in the vars
which indicates "where the process is"
in negotiating the chain of deferred operations.
The longer the chain, the more info must be maintained.

A recursive process is different than a recursive procedure.
Recursive procedures call themselves.
Linearly recursive processes expand and contract due to deferred operations.

Many programming languages interpreters
consume an amount of memory that grows with the number of procedure calls
even when the process described is iterative.
As a consequence, these languages can describe iterative processes
only via special-purpose looping constructs such as
`do`, `repeat`, `until`, `for`, and `while`.

An implementation of Scheme
that can execute an iterative process in constant space
is called tail-recursive.

## 1.2.2 Tree Recursion

Consider this recursive procedure for computing Fibonacci numbers:

```lisp
(define (fib n)
  (cond ((= n 0) 0)
        ((= n 1) 1)
        (else (+ (fib (- n 1))
                 (fib (- n 2))))))
```

To compute `(fib 5)`, compute `(fib 4)` and `(fib 3)`.
To compute `(fib 4)`, compute `(fib 3)` and `(fib 2)`.
The evolved process looks like a tree.
The branches split into two at each level (except at the bottom); this reflects
that the `fib` procedure calls itself twice each time it is invoked.

The number of steps used by the process grows exponentially with the input.
The space required grows linearly with the input.

In general, a tree-recursive process
requires a number of steps proportional to the number of nodes in the tree
and requires space proportional to the maximum depth of the tree.

Consider this linear iteration procedure for computing Fibonacci numbers:

```lisp
(define (fib n)
  (fib-iter 1 0 n))

(define (fib-iter a b count)
  (if (= count 0)
      b
      (fib-iter (+ a b) a (- count 1))))
```

The number of steps used by the process grows linearly with the input.

## 1.2.3 Orders of Growth

One way to describe the difference in the rates
at which processes consume computational resources
is to use the notion of order of growth
to obtain a gross measure of the resources required by a process
as the inputs become larger.

Let `n` be a parameter that measures the size of the problem,
and let `R(n)` be the amount of resources the process requires
for a problem of size `n`.

We say that `R(n)` has order of growth `Θ(f(n))`,
written `R(n) = Θ(f(n))`,
pronounced "theta of `f(n)`".

The steps required and the space required
for the linear recursive process in section 1.2.1
grow as `Θ(n)`.

The steps required for the linear iterative process in section 1.2.1
grow as `Θ(n)` but the space as `Θ(1)` (constant).

The steps required for the tree-recursive process in section 1.2.2
grow as `Θ(1.618^n)` and space as `Θ(n)`.
